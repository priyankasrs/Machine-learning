{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Stump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>playtennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>overcast</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>strong</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook temperature humidity    wind playtennis\n",
       "0       rain        cool   normal  strong         no\n",
       "1       rain        mild     high  strong         no\n",
       "2       rain        mild   normal    weak        yes\n",
       "3      sunny         hot     high  strong         no\n",
       "4      sunny        mild   normal  strong         no\n",
       "5       rain        mild     high    weak        yes\n",
       "6      sunny        cool   normal    weak        yes\n",
       "7   overcast         hot   normal    weak        yes\n",
       "8      sunny         hot     high    weak         no\n",
       "9   overcast        mild     high  strong        yes\n",
       "10  overcast         hot     high    weak        yes\n",
       "11  overcast        cool   normal  strong        yes\n",
       "12     sunny        mild     high  strong         no\n",
       "13      rain        cool   normal    weak        yes\n",
       "14     sunny        mild     high    weak         no"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "array = np.array([('sunny','hot','high','weak','no'),\n",
    "                ('sunny','hot','high','strong','no'),\n",
    "                ('overcast','hot','high','weak','yes'),\n",
    "                ('rain','mild','high','weak','yes'),\n",
    "                ('rain','cool','normal','weak','yes'),\n",
    "                ('rain','cool','normal','strong','no'),\n",
    "                ('overcast','cool','normal','strong','yes'),\n",
    "                ('sunny','mild','high','weak','no'),\n",
    "                ('sunny','cool','normal','weak','yes'),\n",
    "                ('rain','mild','normal','weak','yes'),\n",
    "                ('sunny','mild','normal','strong','no'),\n",
    "                ('overcast','mild','high','strong','yes'),\n",
    "                ('overcast','hot','normal','weak','yes'),\n",
    "                ('rain','mild','high','strong','no'),\n",
    "                ('sunny','mild','high','strong','no')])\n",
    "np.random.shuffle(array)\n",
    "training, test = array[:10,:], array[10:,:]\n",
    "\n",
    "def test_split(test_data):\n",
    "    return test_data[:,:4],test_data[:,4]\n",
    "\n",
    "def train_split(train_data):\n",
    "    return train_data[:,:4],train_data[:,4]\n",
    "\n",
    "X_test, y_test = test_split(test)\n",
    "X_train, y_train = train_split(training)\n",
    "################################################\n",
    "#TO HAVE A BETTER UNDERSTANDING OF THE DATASET\n",
    "################################################\n",
    "play_dict = {'outlook': [], 'temperature': [], 'humidity': [], 'wind': [], 'playtennis': []}\n",
    "\n",
    "for row in array:\n",
    "    play_dict['outlook'].append(row[0])\n",
    "    play_dict['temperature'].append(row[1])\n",
    "    play_dict['humidity'].append(row[2])\n",
    "    play_dict['wind'].append(row[3])\n",
    "    play_dict['playtennis'].append(row[4])\n",
    "                 \n",
    "df = pd.DataFrame(play_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "class DecisionStump:\n",
    "    '''\n",
    "    Decision tree with depth=1 that should be able to handle \n",
    "    discrete data as seen in the data.\n",
    "    \n",
    "    Assumption: All features and target are discrete valued.\n",
    "    \n",
    "    The single node must be chosen using infromation gain and \n",
    "    entropy.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        '''\n",
    "        #print(\"In init\")\n",
    "    \n",
    "    def entropy(self, left, right, total_instances):\n",
    "        # left - no of yeses when split\n",
    "        # right - no of nos when split\n",
    "        # n - no_of_splits\n",
    "        if(left == total_instances or right == total_instances):\n",
    "            return 0\n",
    "        elif(left == right):\n",
    "            return 1\n",
    "        else:\n",
    "            prob_left = -left/total_instances\n",
    "            prob_right = -right/total_instances\n",
    "            #print(prob_right, prob_left,(math.log(left)/math.log(total_instances)))\n",
    "            entropy = prob_left*(math.log(left/total_instances))+ prob_right*(math.log(right/total_instances))\n",
    "            return entropy      \n",
    "    \n",
    "    def information_gain(self, X, Y, feature, classes):\n",
    "        # feature - column no of feature to calculate information gain\n",
    "        #print(\"Inside information gain\")\n",
    "        #print(feature,classes)\n",
    "        dict_of_splits = {}\n",
    "        #print(X,Y)\n",
    "        #print(len(X))\n",
    "        Y = Y.reshape((len(Y),1))\n",
    "        unique, counts = np.unique(Y, return_counts=True)\n",
    "        count_yes_no = dict(zip(unique, counts))\n",
    "        #print(count_yes_no)\n",
    "        #print(Y)\n",
    "        data = np.concatenate((X,Y.reshape((len(Y),1))), axis=1)\n",
    "        #pprint.pprint(data)\n",
    "        \n",
    "        ###################################################################\n",
    "        count_classes_split = {}\n",
    "        for value in classes:\n",
    "            dict_of_splits[value] = []\n",
    "            data_list = []\n",
    "            for row in data:\n",
    "                #print(row[feature])\n",
    "                count_classes_split[value] = 0\n",
    "                if row[feature]==value:\n",
    "                    data_list.append(row.tolist())\n",
    "                    if value in count_classes_split:\n",
    "                        count_classes_split[value] += 1\n",
    "                    else:\n",
    "                        count_classes_split[value] = 1\n",
    "            dict_of_splits[value].append(data_list)\n",
    "            \n",
    "        #pprint.pprint(dict_of_splits)\n",
    "        #pprint.pprint(count_classes_split)\n",
    "        \n",
    "        ##################################################################\n",
    "        information_gain = []\n",
    "        entropy_split = {}\n",
    "        #print(\"--------------------------------------------------------\")\n",
    "        #print(\"current entropy:\",count_yes_no[\"yes\"],count_yes_no[\"no\"])    \n",
    "        current_entropy= self.entropy(count_yes_no.get(\"yes\", 0),count_yes_no.get(\"no\", 0),count_yes_no.get(\"yes\", 0)+count_yes_no.get(\"no\", 0))\n",
    "        #print(current_entropy)\n",
    "        \n",
    "        ##################################################################\n",
    "        classification_feature_split = {}\n",
    "        decision_stump = {}\n",
    "        ##################################################################\n",
    "        for each_class in dict_of_splits.items():\n",
    "            classification_feature_split = {}\n",
    "            class_name, data = each_class\n",
    "            #print(data)\n",
    "            for list_of_lists in data:\n",
    "                for list1 in list_of_lists:\n",
    "                    classification_class = list1[len(list1)-1]\n",
    "                    if classification_class in classification_feature_split:\n",
    "                        classification_feature_split[classification_class] += 1\n",
    "                    else:\n",
    "                        classification_feature_split[classification_class] = 1\n",
    "            #print(\"-------------\")\n",
    "            #print(\"###################\")\n",
    "            #print(class_name)\n",
    "            #pprint.pprint(classification_feature_split)\n",
    "            decision_stump[class_name]=classification_feature_split\n",
    "            ####################################################\n",
    "            \n",
    "        \n",
    "            ####################################################\n",
    "            yes_no = []\n",
    "            '''\n",
    "            for val in classification_feature_split:\n",
    "                print(val)\n",
    "                yes_no.append(classification_feature_split[val])\n",
    "            print(yes_no)\n",
    "            print(\"current entropy:\",classification_feature_split[\"yes\"],classification_feature_split[\"no\"],classification_feature_split[\"yes\"]+classification_feature_split[\"no\"]\n",
    "            \n",
    "            '''\n",
    "            e= self.entropy(classification_feature_split.get(\"yes\", 0),classification_feature_split.get(\"no\", 0),classification_feature_split.get(\"yes\", 0)+classification_feature_split.get(\"no\", 0))\n",
    "                    \n",
    "            entropy_split[class_name]=e\n",
    "             \n",
    "        #print(entropy_split)\n",
    "        summation = 0\n",
    "        for value in count_classes_split:\n",
    "            #print(entropy_split[value],count_classes_split[value])\n",
    "            summation += entropy_split[value]*(count_classes_split[value]/len(X))\n",
    "            #print(\"summation for:\",value,\":\",summation)\n",
    "        return current_entropy - summation, decision_stump\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        #print(\"In fit\")\n",
    "        '''\n",
    "        The fit method takes in two arguments: X is 2 dimensional numpy array, which is the training \n",
    "        instances and Y which is the class labels corresponding to the training instances X.  \n",
    "        Y will be a one dimensional numpy array. \n",
    "        The fit method must take in the training data (X, Y) and build a decision stump.\n",
    "        '''\n",
    "        #print(\"Inside fit\")\n",
    "        if(X is None or Y is None):\n",
    "            print(\"X_train or y_train is empty\")\n",
    "        else:\n",
    "            max_information_gain = 0\n",
    "            max_ig_feature = 0\n",
    "            for i in range(X.shape[1]):\n",
    "                #print(i)\n",
    "                unique, counts = np.unique(X[:,i], return_counts=True)\n",
    "                #print(unique)\n",
    "                ig,decision_stump = self.information_gain(X, Y, i, unique)\n",
    "                #print(\"Information gain for feature\", i,\"is\",ig)\n",
    "                if(ig > max_information_gain):\n",
    "                    max_information_gain = ig\n",
    "                    self.max_ig_feature = i\n",
    "                    self.decision_stump = decision_stump\n",
    "\n",
    "            #print(max_information_gain,i)\n",
    "            unique, counts = np.unique(X[:,self.max_ig_feature], return_counts=True)\n",
    "\n",
    "            #print(unique,self.max_ig_feature)\n",
    "    \n",
    "    def predict(self,X_predict):\n",
    "        #print(\"In predict\",X_predict)\n",
    "        '''\n",
    "         The predict method takes in a set of instances X_predict which has the same dimensions\n",
    "         as the training instances X and will also be a 2-dimensional numpy array. \n",
    "         The predict method must output a one dimensional array of the target classes predicted by \n",
    "         the decision stump, corresponding to each of the X_predict instances.\n",
    "        '''\n",
    "         \n",
    "        #print(self.decision_stump,self.max_ig_feature)\n",
    "        decision_stump = {}\n",
    "        for item in self.decision_stump.items():\n",
    "            key,value = item\n",
    "            maxi = 0\n",
    "            #print(key)\n",
    "            for key1 in value:\n",
    "                #print(key1)\n",
    "                if value[key1]>maxi:\n",
    "                    maxi = value[key1]\n",
    "                    maxi_ans = key1\n",
    "            #print(maxi_ans)\n",
    "            decision_stump[key]=maxi_ans\n",
    "            \n",
    "        y_predict = []\n",
    "        \n",
    "        for row in X_predict[:,self.max_ig_feature]:\n",
    "            y_predict.append(decision_stump[row])\n",
    "            \n",
    "        return y_predict \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DecisionStump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes', 'yes', 'no', 'no', 'no']"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
